# MCM 2026 Problem C - Quick Start Guide

## å¿«é€Ÿå¼€å§‹æŒ‡å—

æœ¬æŒ‡å—å¸®åŠ©æ‚¨å¿«é€Ÿå¼€å§‹ä½¿ç”¨MCMæ•°æ®åˆ†ææ¡†æ¶ã€‚

## æ­¥éª¤ 1: ç¯å¢ƒé…ç½®

### å®‰è£…ä¾èµ–åŒ…

```bash
pip install -r requirements.txt
```

æˆ–è€…æ‰‹åŠ¨å®‰è£…ä¸»è¦ä¾èµ–ï¼š

```bash
pip install pandas numpy scipy matplotlib seaborn scikit-learn xgboost lightgbm statsmodels plotly jupyter
```

## æ­¥éª¤ 2: è¿è¡Œåˆ†æ

### æ–¹æ³• A: è¿è¡Œå®Œæ•´åˆ†ææµç¨‹ï¼ˆæ¨èï¼‰

ä¸€æ¬¡æ€§è¿è¡Œæ‰€æœ‰åˆ†ææ¨¡å—ï¼š

```bash
python main.py --all
```

è¿™å°†æ‰§è¡Œï¼š
1. æ•°æ®é¢„å¤„ç†
2. æ¢ç´¢æ€§æ•°æ®åˆ†æ
3. ç»Ÿè®¡å»ºæ¨¡
4. é¢„æµ‹å»ºæ¨¡
5. æ¨¡å‹è¯„ä¼°
6. æ•°æ®å¯è§†åŒ–

é¢„è®¡è€—æ—¶ï¼š5-10åˆ†é’Ÿ

### æ–¹æ³• B: åˆ†æ­¥è¿è¡Œ

å¦‚æœä½ æƒ³å•ç‹¬è¿è¡ŒæŸä¸ªæ¨¡å—ï¼š

```bash
# ä»…æ•°æ®é¢„å¤„ç†
python main.py --preprocess

# ä»…æ¢ç´¢æ€§æ•°æ®åˆ†æ
python main.py --eda

# ä»…ç»Ÿè®¡å»ºæ¨¡
python main.py --statistical

# ä»…é¢„æµ‹å»ºæ¨¡
python main.py --predict

# ä»…æ¨¡å‹è¯„ä¼°
python main.py --evaluate

# ä»…å¯è§†åŒ–
python main.py --visualize
```

### æ–¹æ³• C: åœ¨Pythonä¸­é€æ­¥è¿è¡Œ

```python
# 1. æ•°æ®é¢„å¤„ç†
from src.data_preprocessing import DWTSDataPreprocessor

preprocessor = DWTSDataPreprocessor()
processed_data = preprocessor.process()
preprocessor.save_processed_data()

# 2. æ¢ç´¢æ€§æ•°æ®åˆ†æ
from src.exploratory_analysis import EDAnalyzer

analyzer = EDAnalyzer()
analyzer.run_full_analysis()

# 3. ç»Ÿè®¡å»ºæ¨¡
from src.statistical_models import StatisticalModeler

modeler = StatisticalModeler()
modeler.run_all_models()

# 4. é¢„æµ‹å»ºæ¨¡
from src.prediction_models import PredictionModeler

predictor = PredictionModeler()
predictor.run_all_models()

# 5. æ¨¡å‹è¯„ä¼°
from src.model_evaluation import ModelEvaluator

evaluator = ModelEvaluator()
evaluator.run_full_evaluation()

# 6. å¯è§†åŒ–
from src.visualization import Visualizer

visualizer = Visualizer()
visualizer.generate_all_visualizations()
```

## æ­¥éª¤ 3: æŸ¥çœ‹ç»“æœ

### ç”Ÿæˆçš„æ–‡ä»¶

è¿è¡Œå®Œæˆåï¼Œæ‚¨å°†è·å¾—ï¼š

#### æ•°æ®æ–‡ä»¶
- `data/processed_data.csv` - å¤„ç†åçš„æ•°æ®

#### å›¾è¡¨æ–‡ä»¶ï¼ˆresults/figures/ï¼‰
- `distribution_analysis.png` - åˆ†å¸ƒç‰¹å¾åˆ†æ
- `correlation_matrix.png` - ç›¸å…³æ€§çƒ­å›¾
- `score_trend_by_week.png` - å„å‘¨è¯„åˆ†è¶‹åŠ¿
- `linear_regression_results.png` - çº¿æ€§å›å½’ç»“æœ
- `anova_industry_scores.png` - è¡Œä¸šåˆ†æ
- `ridge_regression_alpha.png` - å²­å›å½’å‚æ•°ä¼˜åŒ–
- `rf_feature_importance.png` - ç‰¹å¾é‡è¦æ€§ï¼ˆéšæœºæ£®æ—ï¼‰
- `model_comparison.png` - æ¨¡å‹æ€§èƒ½å¯¹æ¯”
- `cross_validation_results.png` - äº¤å‰éªŒè¯ç»“æœ
- `residual_analysis.png` - æ®‹å·®åˆ†æ
- `learning_curve.png` - å­¦ä¹ æ›²çº¿
- `score_evolution_top_10.png` - Top10é€‰æ‰‹è¯„åˆ†æ¼”å˜
- `age_vs_performance.png` - å¹´é¾„ä¸è¡¨ç°å…³ç³»
- `industry_analysis.png` - è¡Œä¸šåˆ†æ
- `season_trends.png` - èµ›å­£è¶‹åŠ¿
- `score_distribution_by_week.png` - å„å‘¨è¯„åˆ†åˆ†å¸ƒ
- `interactive_dashboard.html` - äº¤äº’å¼ä»ªè¡¨æ¿

#### æ–‡æ¡£ï¼ˆpaper/ï¼‰
- `data_analysis_summary.md` - æ•°æ®åˆ†ææ€»ç»“
- `statistical_insights.md` - ç»Ÿè®¡æ´å¯Ÿä¸å»ºæ¨¡æ€»ç»“

## æ­¥éª¤ 4: ä½¿ç”¨ç»“æœæ’°å†™è®ºæ–‡

### è®ºæ–‡ç»“æ„å»ºè®®

```
1. Introduction
   - é—®é¢˜èƒŒæ™¯
   - ç ”ç©¶ç›®æ ‡
   
2. Data Description
   - ä½¿ç”¨: data_analysis_summary.md ç¬¬1èŠ‚
   - å›¾è¡¨: distribution_analysis.png
   
3. Exploratory Data Analysis
   - ä½¿ç”¨: data_analysis_summary.md ç¬¬2èŠ‚
   - å›¾è¡¨: correlation_matrix.png, score_trend_by_week.png
   
4. Feature Engineering
   - ä½¿ç”¨: data_analysis_summary.md ç¬¬3èŠ‚
   - å›¾è¡¨: rf_feature_importance.png
   
5. Methodology
   - ä½¿ç”¨: statistical_insights.md ç¬¬1-2èŠ‚
   - å›¾è¡¨: model_comparison.png
   
6. Results
   - ä½¿ç”¨: statistical_insights.md ç¬¬3èŠ‚
   - å›¾è¡¨: linear_regression_results.png, anova_industry_scores.png
   
7. Model Validation
   - ä½¿ç”¨: statistical_insights.md ç¬¬4èŠ‚
   - å›¾è¡¨: cross_validation_results.png, residual_analysis.png
   
8. Discussion & Conclusion
   - ä½¿ç”¨: data_analysis_summary.md ç¬¬4èŠ‚
```

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•ä¿®æ”¹æ¨¡å‹å‚æ•°ï¼Ÿ

ç¼–è¾‘å¯¹åº”çš„Pythonæ¨¡å—ï¼ˆå¦‚ `src/prediction_models.py`ï¼‰ï¼Œä¿®æ”¹æ¨¡å‹é…ç½®éƒ¨åˆ†ã€‚

### Q2: å¦‚ä½•æ·»åŠ æ–°ç‰¹å¾ï¼Ÿ

åœ¨ `src/data_preprocessing.py` çš„ `extract_score_features` æ–¹æ³•ä¸­æ·»åŠ ã€‚

### Q3: å¦‚ä½•è‡ªå®šä¹‰å¯è§†åŒ–ï¼Ÿ

ä¿®æ”¹ `src/visualization.py`ï¼Œæ·»åŠ æ–°çš„ç»˜å›¾å‡½æ•°ã€‚

### Q4: å›¾è¡¨æ˜¾ç¤ºä¸­æ–‡ä¹±ç æ€ä¹ˆåŠï¼Ÿ

åœ¨ä»£ç å¼€å¤´æ·»åŠ ï¼š
```python
import matplotlib.pyplot as plt
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']  # Mac/Linux/Windows
```

### Q5: å†…å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

å‡å°‘æ¨¡å‹å¤æ‚åº¦ï¼š
- é™ä½ `n_estimators`
- å‡å° `max_depth`
- ä½¿ç”¨æ›´å°çš„äº¤å‰éªŒè¯æŠ˜æ•°

## è¿›é˜¶ä½¿ç”¨

### è¶…å‚æ•°ä¼˜åŒ–

```python
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor

# å®šä¹‰å‚æ•°ç½‘æ ¼
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [5, 10, 15],
    'min_samples_split': [2, 5, 10]
}

# ç½‘æ ¼æœç´¢
model = RandomForestRegressor(random_state=42)
grid_search = GridSearchCV(model, param_grid, cv=5, scoring='r2', n_jobs=-1)
grid_search.fit(X_train, y_train)

print(f"æœ€ä½³å‚æ•°: {grid_search.best_params_}")
print(f"æœ€ä½³åˆ†æ•°: {grid_search.best_score_}")
```

### ç‰¹å¾é€‰æ‹©

```python
from sklearn.feature_selection import SelectKBest, f_regression

# é€‰æ‹©Kä¸ªæœ€ä½³ç‰¹å¾
selector = SelectKBest(score_func=f_regression, k=5)
X_selected = selector.fit_transform(X, y)

# æŸ¥çœ‹é€‰ä¸­çš„ç‰¹å¾
selected_features = X.columns[selector.get_support()]
print(f"é€‰ä¸­çš„ç‰¹å¾: {selected_features}")
```

### SHAPå€¼åˆ†æï¼ˆæ¨¡å‹è§£é‡Šï¼‰

```python
import shap

# è®­ç»ƒæ¨¡å‹
model = xgb.XGBRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# è®¡ç®—SHAPå€¼
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)

# å¯è§†åŒ–
shap.summary_plot(shap_values, X_test)
```

## è·å–å¸®åŠ©

å¦‚æœé‡åˆ°é—®é¢˜ï¼š
1. æŸ¥çœ‹ä»£ç ä¸­çš„æ–‡æ¡£å­—ç¬¦ä¸²
2. é˜…è¯» `paper/` ç›®å½•ä¸‹çš„æ–‡æ¡£
3. æ£€æŸ¥é”™è¯¯ä¿¡æ¯å’Œå †æ ˆè·Ÿè¸ª
4. ç¡®ä¿æ‰€æœ‰ä¾èµ–åŒ…å·²æ­£ç¡®å®‰è£…

## ç¥ä½ åœ¨MCMç«èµ›ä¸­å–å¾—å¥½æˆç»©ï¼ğŸ‰
